{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit recognizer using Neural Networks [IN PROGRESS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the mnist dataset from kaggle to recognize digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
      "0      1       0       0       0       0       0       0       0       0   \n",
      "1      0       0       0       0       0       0       0       0       0   \n",
      "2      1       0       0       0       0       0       0       0       0   \n",
      "3      4       0       0       0       0       0       0       0       0   \n",
      "4      0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
      "0       0    ...            0         0         0         0         0   \n",
      "1       0    ...            0         0         0         0         0   \n",
      "2       0    ...            0         0         0         0         0   \n",
      "3       0    ...            0         0         0         0         0   \n",
      "4       0    ...            0         0         0         0         0   \n",
      "\n",
      "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0         0  \n",
      "1         0         0         0         0         0  \n",
      "2         0         0         0         0         0  \n",
      "3         0         0         0         0         0  \n",
      "4         0         0         0         0         0  \n",
      "\n",
      "[5 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images = data.iloc[:,1:].values\n",
    "images = images.astype(np.float)\n",
    "\n",
    "images = np.multiply(images,1.0/255.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image size : 784\n",
      "Image height: 28 \n",
      "Image Width: 28\n"
     ]
    }
   ],
   "source": [
    "image_size = images.shape[1]\n",
    "image_height = image_width = np.ceil(np.sqrt(image_size)).astype(np.uint8)\n",
    "print(\"Image size : {0}\".format(image_size))\n",
    "print(\"Image height: {0} \\nImage Width: {1}\".format(image_height,image_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6064635690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display(img):\n",
    "    one_image = img.reshape(image_width,image_height)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(one_image,cmap=cm.binary)\n",
    "display(images[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels:42000\n",
      "labels[3]:4\n"
     ]
    }
   ],
   "source": [
    "labels = data['label'].values\n",
    "print('labels:{0}'.format(len(labels)))\n",
    "print('labels[3]:{0}'.format(labels[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels_unique:10\n",
      "labels_shape:(42000,)\n"
     ]
    }
   ],
   "source": [
    "labels_unique = np.unique(labels).shape[0]\n",
    "print('labels_unique:{0}'.format(labels_unique))\n",
    "print('labels_shape:{0}'.format(labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting class labels from scalar to one-hot vectors[understand]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     0     10     20 ..., 419970 419980 419990]\n",
      "(42000, 10)\n",
      "labels_new[3]:[ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      "labels_new_shape:(42000, 10)\n"
     ]
    }
   ],
   "source": [
    "def dense_to_hot(labels,labels_unique):\n",
    "    labels_count = labels.shape[0]\n",
    "    index_offset = np.arange(labels_count)*labels_unique\n",
    "    print(index_offset)\n",
    "    # a new array with 42000 rows and 10 columns with each element being zero\n",
    "    labels_modified = np.zeros((labels_count,labels_unique))\n",
    "    print(labels_modified.shape)\n",
    "    # replacing nth digit with 1 for n label\n",
    "    labels_modified.flat[index_offset+labels.ravel()]=1\n",
    "    return labels_modified\n",
    "\n",
    "labels_new = dense_to_hot(labels,labels_unique) \n",
    "print('labels_new[3]:{0}'.format(labels_new[3]))\n",
    "print('labels_new_shape:{0}'.format(labels_new.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The function dense_to_hot converts the label array to a new modified 2d array with 42000 rows and 10 columns.Every element is initially assigned 0.Each element n is defined by replacing 0 with 1 at the nth place.for instance:\n",
    "### 0={1,0,0,0,0,0,0,0,0,0}\n",
    "### 1={0,1,0,0,0,0,0,0,0,0}\n",
    "### 2={0,0,1,0,0,0,0,0,0,0}\n",
    "### .\n",
    "### .\n",
    "### 9={0,0,0,0,0,0,0,0,0,1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_images = images[:2000]\n",
    "test_labels = labels_new[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_images = images[2000:]\n",
    "train_labels = labels_new[2000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_images:(40000, 784)\n",
      "train_labels:(40000, 10)\n"
     ]
    }
   ],
   "source": [
    "print('train_images:{0}'.format(train_images.shape))\n",
    "print('train_labels:{0}'.format(train_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_images:(2000, 784)\n",
      "test_labels:(2000, 10)\n"
     ]
    }
   ],
   "source": [
    "print('test_images:{0}'.format(test_images.shape))\n",
    "print('test_labels:{0}'.format(test_labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
